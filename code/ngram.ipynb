{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffa1950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, ngrams, everygrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
    "from nltk.lm import MLE, KneserNeyInterpolated, Lidstone, Laplace, AbsoluteDiscountingInterpolated\n",
    "\n",
    "import lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e2490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dzionek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707c77b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logic</td>\n",
       "      <td>​man i is</td>\n",
       "      <td>knockin doors down showin parts around\\nima co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Roots</td>\n",
       "      <td>The Seed</td>\n",
       "      <td>i\\nknocked up 9 months ago\\nand what she finna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fabolous</td>\n",
       "      <td>Diced Pineapples</td>\n",
       "      <td>shawty so cold pussy winter fresh\\nreservation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>Roman Reloaded</td>\n",
       "      <td>bang my shit bang it bangbang\\nbang my shit ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MC Lyte</td>\n",
       "      <td>Ride Wit Me</td>\n",
       "      <td>lytro yeah hm yo\\nyeah fuck the rest be nobody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16872</th>\n",
       "      <td>Joey BadA$$</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>and i guess its my turn to shine\\nthe bright l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16873</th>\n",
       "      <td>Ludacris</td>\n",
       "      <td>Southern Fried Intro</td>\n",
       "      <td>hey yeah i want all you proud sistas to stand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>Dr. Dre</td>\n",
       "      <td>Lyrical Gangbang</td>\n",
       "      <td>this should be played at high volume\\npreferab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>J Cole</td>\n",
       "      <td>LAnd of the Snakes</td>\n",
       "      <td>yeah uhhuh\\nthis the shit i used to roll down ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16876</th>\n",
       "      <td>Brother Ali</td>\n",
       "      <td>Uncle Usi Taught Me</td>\n",
       "      <td>mmhmm\\nuncle usi taught me\\ncant teach what yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16877 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist                  song  \\\n",
       "0            Logic             ​man i is   \n",
       "1        The Roots              The Seed   \n",
       "2         Fabolous      Diced Pineapples   \n",
       "3      Nicki Minaj        Roman Reloaded   \n",
       "4          MC Lyte           Ride Wit Me   \n",
       "...            ...                   ...   \n",
       "16872  Joey BadA$$             Satellite   \n",
       "16873     Ludacris  Southern Fried Intro   \n",
       "16874      Dr. Dre      Lyrical Gangbang   \n",
       "16875       J Cole    LAnd of the Snakes   \n",
       "16876  Brother Ali   Uncle Usi Taught Me   \n",
       "\n",
       "                                                   lyric  \n",
       "0      knockin doors down showin parts around\\nima co...  \n",
       "1      i\\nknocked up 9 months ago\\nand what she finna...  \n",
       "2      shawty so cold pussy winter fresh\\nreservation...  \n",
       "3      bang my shit bang it bangbang\\nbang my shit ba...  \n",
       "4      lytro yeah hm yo\\nyeah fuck the rest be nobody...  \n",
       "...                                                  ...  \n",
       "16872  and i guess its my turn to shine\\nthe bright l...  \n",
       "16873  hey yeah i want all you proud sistas to stand ...  \n",
       "16874  this should be played at high volume\\npreferab...  \n",
       "16875  yeah uhhuh\\nthis the shit i used to roll down ...  \n",
       "16876  mmhmm\\nuncle usi taught me\\ncant teach what yo...  \n",
       "\n",
       "[16877 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65e083",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ea2df",
   "metadata": {},
   "source": [
    "Default word tokenizer removes new line symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3646725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# lyric = [word_tokenize(line) + ['\\n'] for line in train['lyric'][0].split('\\n')]\n",
    "# flat_list = list(itertools.chain(*lyric))[:-1]  # remove last new line symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce01738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataset):\n",
    "    return [\n",
    "        nltk.flatten(([\n",
    "            word_tokenize(line) + ['\\n']\n",
    "            for line in lyric.split('\\n')\n",
    "        ]))[:-1]\n",
    "        for lyric in list(dataset['lyric'])\n",
    "        if not isinstance(lyric, float)  # remove nan values\n",
    "    ]\n",
    "\n",
    "tokenized_train = tokenize(train_df)\n",
    "tokenized_test = tokenize(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f939fbc",
   "metadata": {},
   "source": [
    "## Setup and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c758b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9314dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(dataset, every=False):\n",
    "    if every:\n",
    "        return [list(everygrams(pad_both_ends(example, n=N), max_len=N)) for example in dataset]\n",
    "    else:\n",
    "        return [list(ngrams(pad_both_ends(example, n=N), n=N)) for example in dataset]\n",
    "\n",
    "train_ngrams = generate_ngrams(tokenized_train, every=True)\n",
    "test_ngrams = generate_ngrams(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f282f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocabulary(dataset):\n",
    "    return list(nltk.lm.preprocessing.flatten(pad_both_ends(example, n=N) for example in dataset))\n",
    "\n",
    "train_vocabulary = generate_vocabulary(tokenized_train)\n",
    "test_vocabulary = generate_vocabulary(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea2f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 101176 distinct tokens.\n",
      "Test set contains 52342 distinct tokens.\n",
      "Test set has 11684 tokens not in train test.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set contains\", len(set(train_vocabulary)), \"distinct tokens.\")\n",
    "print(\"Test set contains\", len(set(test_vocabulary)), \"distinct tokens.\")\n",
    "print(\"Test set has\", len(set(test_vocabulary) - set(train_vocabulary)), \"tokens not in train test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a7f995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 1155857),\n",
       " ('the', 373895),\n",
       " ('i', 311584),\n",
       " ('you', 239336),\n",
       " ('a', 208618),\n",
       " ('and', 183033),\n",
       " ('to', 173764),\n",
       " ('my', 148695),\n",
       " ('it', 127058),\n",
       " ('me', 123936)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_vocabulary).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a97e08",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddce41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Lidstone(1e-4, N)\n",
    "lm.fit(train_ngrams, train_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "675f3de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101177"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5d54f",
   "metadata": {},
   "source": [
    "## Quantitative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa3e53",
   "metadata": {},
   "source": [
    "### Perplexity (PPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d344b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.59839790243956"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(nltk.lm.preprocessing.flatten(train_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "792a8e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943.0695898938937"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(nltk.lm.preprocessing.flatten(test_ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4544cf",
   "metadata": {},
   "source": [
    "### Generate songs after first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04fd0475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me a chance roll the dice over hang it back\\nthe child will be illest in your clothes slugs ripping through your\\neast new york citycity new york ridin on the cock\\nho you want me to the polo fleece to the block i walk into the palms\\nremain calm\\nheaded to the toes and never keep it in the jacket she smoke trees considerably\\ni just paused to scratch a record label told him switch dials\\nwoo yeah\\nhot boys\\nthe judge here comes the hot whips ahh\\ni'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=['I', 'found'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df98d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_lines = [song[:song.index('\\n')+1] for song in tokenized_test if '\\n' in song]\n",
    "len(first_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4dde3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['godfathers', 'in', 'the', 'house', '\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62cce3f",
   "metadata": {},
   "source": [
    "Generate all continuations of rap songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7beaf3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for first_line in first_lines:\n",
    "    result = ' '.join(first_line)[:-2] + '\\n'\n",
    "    result += re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=first_line, random_seed=0)))\n",
    "    result = re.sub(' </s>.*', '', result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fa7e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alright we gather here around the midnight hour\n",
      "this rap shit\n",
      "like i still fuck the plug told her hello and then i walk with tall tops\n",
      "silver tops tan tops aqua tops orange tops\n",
      "just to get this money\n",
      "so if you out\n",
      "kool moe dee\n",
      "two cups nigga\n",
      "you see me\n",
      "how many wan na know what it seems like your mans missing plans thicken\n",
      "while im eating 50 fried clam\n",
      "but there were two perfect kids in the funky output\n",
      "five thousand volt thunderbolts\n",
      "you got ta worry dont worry about my issue\n"
     ]
    }
   ],
   "source": [
    "print(results[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f3f1c",
   "metadata": {},
   "source": [
    "### Rhyme Density (RD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb9d4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rd = np.array([lyrics.get_rhyme_density(song) for song in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f82a04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(results_rd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76c9012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(results_rd),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6d1c4",
   "metadata": {},
   "source": [
    "### Syllable Count Difference (SCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24132960",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scd = np.array([lyrics.get_syllable_count_difference(song) for song in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "588aa96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.52"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(results_scd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c1937a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.34"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(results_scd),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb6bbd",
   "metadata": {},
   "source": [
    "### Longest Rhyme (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee6a1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr = np.array([lyrics.get_longest_rhyme(song) for song in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b9519f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.31 0.67\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(results_lr),2), round(np.std(results_lr),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4a359",
   "metadata": {},
   "source": [
    "### Unique Words (UW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f36df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_uw = np.array([lyrics.get_unique_words(song) for song in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0114cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.06\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(results_uw),2), round(np.std(results_uw),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152996ff",
   "metadata": {},
   "source": [
    "### Get those statistics for training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e0518",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbdd8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rd = np.array([\n",
    "    lyrics.get_rhyme_density(song)\n",
    "    for song in train_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f07ecf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(train_rd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a6b4dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(train_rd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbd0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scd = np.array([\n",
    "    lyrics.get_syllable_count_difference(song)\n",
    "    for song in train_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ab68d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.76"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(train_scd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70ef7998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(train_scd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "313f9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lr = np.array([\n",
    "    lyrics.get_longest_rhyme(song)\n",
    "    for song in train_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0e7579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.15 1.2\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(train_lr),2), round(np.std(train_lr),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7681a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uw = np.array([\n",
    "    lyrics.get_unique_words(song)\n",
    "    for song in train_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "180cf6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44 0.1\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(train_uw),2), round(np.std(train_uw),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80414d3",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7738648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rd = np.array([\n",
    "    lyrics.get_rhyme_density(song)\n",
    "    for song in test_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46d32630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(test_rd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93fb44de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(test_rd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e150fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scd = np.array([\n",
    "    lyrics.get_syllable_count_difference(song)\n",
    "    for song in test_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62ab4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.74"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(test_scd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68a4d20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.28"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(test_scd),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76219d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lr = np.array([\n",
    "    lyrics.get_longest_rhyme(song)\n",
    "    for song in test_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4988fc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 1.2\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(test_lr),2), round(np.std(test_lr),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30d673f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uw = np.array([\n",
    "    lyrics.get_unique_words(song)\n",
    "    for song in test_df['lyric']\n",
    "    if isinstance(song, str) and '\\n' in song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ba207c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44 0.1\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(test_uw),2), round(np.std(test_uw),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7c76a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ice-T</td>\n",
       "      <td>Pimpin’ Ain’t Easy [Godfather Theme]</td>\n",
       "      <td>godfathers in the house\\ngrab yo bitches\\npimp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jean Grae</td>\n",
       "      <td>What You Came For</td>\n",
       "      <td>tell me what ya\\ntell me what ya\\ntell me what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lil' Wayne</td>\n",
       "      <td>How to Love</td>\n",
       "      <td>cut the music up\\na little louder yeah\\nyou ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-40</td>\n",
       "      <td>Gas, Break, Dip</td>\n",
       "      <td>calling all hustlers calling all players\\nple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lil' Kim</td>\n",
       "      <td>Spicy</td>\n",
       "      <td>muy caliente\\ntime to keep it cool thats what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>Gang Starr</td>\n",
       "      <td>Check the Technique</td>\n",
       "      <td>you puny protozoa youre so minute you didnt kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>Big Sean</td>\n",
       "      <td>Jit/Juke</td>\n",
       "      <td>ho i got my cell phone ringin nowadays its har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>Gang Starr</td>\n",
       "      <td>Put Up or Shut Up</td>\n",
       "      <td>stupid you know its time to sit and think befo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Free Smoke</td>\n",
       "      <td>is it the strength of your feelings\\noverthrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>Nipsey Hussle</td>\n",
       "      <td>Hate It or Love It</td>\n",
       "      <td>my face fat that means im eating  where your s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4220 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                                  song  \\\n",
       "0             Ice-T  Pimpin’ Ain’t Easy [Godfather Theme]   \n",
       "1         Jean Grae                     What You Came For   \n",
       "2        Lil' Wayne                           How to Love   \n",
       "3              E-40                       Gas, Break, Dip   \n",
       "4          Lil' Kim                                 Spicy   \n",
       "...             ...                                   ...   \n",
       "4215     Gang Starr                   Check the Technique   \n",
       "4216       Big Sean                              Jit/Juke   \n",
       "4217     Gang Starr                     Put Up or Shut Up   \n",
       "4218          Drake                            Free Smoke   \n",
       "4219  Nipsey Hussle                    Hate It or Love It   \n",
       "\n",
       "                                                  lyric  \n",
       "0     godfathers in the house\\ngrab yo bitches\\npimp...  \n",
       "1     tell me what ya\\ntell me what ya\\ntell me what...  \n",
       "2     cut the music up\\na little louder yeah\\nyou ha...  \n",
       "3      calling all hustlers calling all players\\nple...  \n",
       "4      muy caliente\\ntime to keep it cool thats what...  \n",
       "...                                                 ...  \n",
       "4215  you puny protozoa youre so minute you didnt kn...  \n",
       "4216  ho i got my cell phone ringin nowadays its har...  \n",
       "4217  stupid you know its time to sit and think befo...  \n",
       "4218  is it the strength of your feelings\\noverthrow...  \n",
       "4219  my face fat that means im eating  where your s...  \n",
       "\n",
       "[4220 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5c2fd",
   "metadata": {},
   "source": [
    "## Qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d00f00bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what what what\n",
      "got fly hoes kneel\n",
      "stand your loneliness\n",
      "im holding you down to a 50000\n",
      "check it yo\n",
      "jump from gee to gee\n",
      "so im like all about bacon or sausage\n",
      "the ultimate freak off\n",
      "wave em round before you fuck that we just laying\n",
      "and im the best\n",
      "my lady say its up there to settle\n",
      "now we pawns in this shit for me baby its okay\n",
      "alright one more hit\n",
      "ayy put two pills and im so thankful\n",
      "for gods were el\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=['cut', 'the', 'music', 'up', '\\n']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e62d73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey yo cause im on that\n",
      "i know my language\n",
      "but i stay on the top down riding clean\n",
      "its goin down\n",
      "about the fresh trim at\n",
      "bitch im a savage\n",
      "aint nothing wrong with the vibe aint no guards playin cards aint no more exceptions\n",
      "losing my balance\n",
      "just rockin it\n",
      "having you be hangin in bars naked for dollars\n",
      "breakin all these bitches is insane\n",
      "a young og then i see you looking for me\n",
      "day ta day\n",
      "clown dont make you do baby is\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=['godfather', 'in', 'the', 'house', '\\n']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ab0a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['godfathers', 'in', 'the', 'house', '\\n']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b922aa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sample number 1 ###\n",
      "godfathers in the house\n",
      "i guess she realized living was hard times\n",
      "as we move too fast\n",
      "eds dead </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "### Sample number 1 ###\n",
      "tell me what ya\n",
      "you got ta follow\n",
      "anywhere im at the crap tables down\n",
      "the shit that i rhyme i get it ive been running from nothing\n",
      "i got ta get back is the film gon feel different\n",
      "pretend im not sexy\n",
      "but im makin sure youre gon na stay and listen to me\n",
      "you aint care\n",
      "nobody wants to get high with my eyes sparkly like a cloak cause murder is murder\n",
      "momma found four shells\n",
      "yea we party right all damn night i get pussy like a groupie\n",
      "i need a\n",
      "\n",
      "### Sample number 1 ###\n",
      "cut the music up\n",
      "but like i be at your homeboy a second\n",
      "check check check check check\n",
      "aap ferg you nasty\n",
      "let the thing\n",
      "i wish you could turn this into somethin\n",
      "then i might do if god were one of them niggas up in the zone now\n",
      "cause in my illustrious career\n",
      "cause youre never gon na rock i wan na then im gone im gone youre tired\n",
      "build on\n",
      "her head was on your back go back down\n",
      "i say my d\n",
      "i see your car and drove off \n",
      "\n",
      "\n",
      "### Sample number 1 ###\n",
      "calling all hustlers calling all players\n",
      "flash the roll\n",
      "catch a feelin i wont budge no lord\n",
      "i carry it\n",
      "dubs cool but told me that death comes wicked painful and slow\n",
      "spending all my cousins\n",
      "dyin inside\n",
      "you can see me and boss my pheromones secrete elon musk so high\n",
      "ive been the past and i said\n",
      "miami estate house by the bruiser\n",
      "teflon vest too\n",
      "now im attributin mo fame than them you would be borin\n",
      "girl i need a fivestar bitch man word like thesaurus\n",
      "pharoahe put fire to that it\n",
      "\n",
      "### Sample number 1 ###\n",
      "muy caliente\n",
      "jaydolf spitler rap hitler\n",
      "im smokin nigga </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "### Sample number 1 ###\n",
      "yeah\n",
      "from new rochelle bust slugs from all the prisons when conditions werent improvin started lootin and the pyramids of giza\n",
      "fila sweats 88 i rocked her to talk so dont get close on the wrong thing and you was gabbling\n",
      "look i was strikin out for games\n",
      "i just aint the same guns that spray shit\n",
      "they dont get down girl\n",
      "you so just quote it\n",
      "heard you like me\n",
      "primo laced me ski did too\n",
      "remember when you got ta keep a ready clip\n",
      "see me rolling in the mactown\n",
      "\n",
      "### Sample number 1 ###\n",
      "g yo bus i think i got itthe answer to all my problems\n",
      "bitch now\n",
      "zoovie niggas aint know me bro\n",
      "motherfuckers need to count it off tracks fuck it lets get lost in my city even out\n",
      "still fuck these niggas on accident\n",
      "pump the temp\n",
      "northside nigga til i get paid\n",
      "and im aware of a poet\n",
      "threes not a pretty gang at sues rendezvous\n",
      "now fuck on me\n",
      "cause in a rut\n",
      "which pen should i know aint nobody heard of us our dwellin inside of me\n",
      "whatever gets you blasted the fastest\n",
      "keep your guard down and\n",
      "\n",
      "### Sample number 1 ###\n",
      "its that candy paint 84s\n",
      "yall betta\n",
      "sheek what yall talkin about some new funk\n",
      "in my dreamin all my la ho\n",
      "all my niggas want my mother with running laps\n",
      "verse 2\n",
      "she make that nigga dre cant stop til my feet feels so nice tell that you cant be your knight in shinnin armor\n",
      "and she got a nickel rock\n",
      "im wearing black paint\n",
      "ice cream\n",
      "theres a certain power presence that he do it again\n",
      "back against the wall\n",
      "i want you to jump you say no\n",
      "i have a\n",
      "\n",
      "### Sample number 1 ###\n",
      "alright we gather here around the midnight hour\n",
      "pussy pop\n",
      "love is unconditional\n",
      "when she came back as blessings or to mention\n",
      "i fly i fly high im blazin\n",
      "it get it before they ruined the crew of the month\n",
      "and now i lay you down on your steps give you more of the street\n",
      "niggas need to scream and shout straighten it\n",
      "we are really special\n",
      "only way out\n",
      "mc ren straight outta broadward\n",
      "then i became bane\n",
      "they youngbloods\n",
      "but they still continue\n",
      "not a publicity stunt\n",
      "ill sign the deal for\n",
      "\n",
      "### Sample number 1 ###\n",
      "peace beat me is something you wont be able to accomplish\n",
      "his only disguise\n",
      "im addicted to chillin make a change somewhat of a cyber girl </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'### Sample number {seed+1} ###')\n",
    "    print(' '.join(first_lines[i])[:-2])\n",
    "    print(re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=first_lines[i]))))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
